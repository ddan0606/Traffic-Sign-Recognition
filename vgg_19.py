# -*- coding: utf-8 -*-
"""vgg_19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CoK1V4nORu1defUe765YXIaW_sgERmuE

# VGG-19
"""

pip install visualkeras

# Framework
import tensorflow as tf
import sklearn

# Visualization
import seaborn as sns
import visualkeras
import matplotlib.pyplot as plt

# Data processing
import numpy as np

data_dir = '/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/traffic_Data/data'
test_dir = '/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/traffic_Data/test'

img_size = 224
batch = 32

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255,
                                                                horizontal_flip = True,
                                                                vertical_flip = True,
                                                                validation_split = 0.2,
                                                                shear_range = 0.1,
                                                                zoom_range = 0.1,
                                                                width_shift_range = 0.1,
                                                                height_shift_range = 0.1)

valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255,
                                                                validation_split = 0.2)

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255)

train_datagen = train_datagen.flow_from_directory(data_dir,
                                                  shuffle = True,
                                                  target_size = (img_size, img_size),
                                                  subset = 'training',
                                                  batch_size = batch,
                                                  class_mode = 'categorical')

valid_datagen = valid_datagen.flow_from_directory(data_dir,
                                                  shuffle = True,
                                                  target_size = (img_size, img_size),
                                                  subset = 'validation',
                                                  batch_size = batch,
                                                  class_mode = 'categorical')

test_datagen = test_datagen.flow_from_directory(test_dir,
                                                shuffle = True,
                                                batch_size = batch,
                                                target_size = (img_size, img_size),
                                                class_mode = 'categorical')

vgg_19 = tf.keras.applications.VGG19(weights = 'imagenet',
                                     include_top = False,
                                     input_shape = (img_size, img_size, 3))

for layer in vgg_19.layers:
    layer.trainable = False

for (i, layer) in enumerate(vgg_19.layers):
    print(str(i) + " " + layer.__class__.__name__, layer.trainable)

def add_classification_layer(bottom_model, num_classes):
    top_model = bottom_model.output
    top_model = tf.keras.layers.Flatten(name = "flatten")(top_model)
    top_model = tf.keras.layers.Dense(256, activation = "relu")(top_model)
    top_model = tf.keras.layers.Dropout(0.3)(top_model)
    top_model = tf.keras.layers.Dense(num_classes, activation = "softmax")(top_model)
    return top_model

num_classes = 5

outputs = add_classification_layer(vgg_19, num_classes)

vgg_19 = tf.keras.models.Model(inputs = vgg_19.input, outputs = outputs)

vgg_19.compile(optimizer = tf.keras.optimizers.Adam(),
               loss = 'categorical_crossentropy',
               metrics = ['accuracy'])

vgg_19.summary()

visualkeras.layered_view(vgg_19, to_file = '/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/model_Architecture/vgg_19.png', legend = True)

filepath = "/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/model/vgg_19.h5"

checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,
                                                verbose = 1,
                                                save_best_only = True,
                                                mode = 'max',
                                                patience = 3)

callbacks_list = [checkpoint]

epochs = 5

history = vgg_19.fit(train_datagen,
                     epochs = epochs,
                     validation_data = valid_datagen,
                     callbacks = callbacks_list)

vgg_19.save("/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/model/vgg_19.h5")

loss, accuracy = vgg_19.evaluate(test_datagen)

print("Loss: {:.2f}".format(loss))
print("Accuracy: {:.2f}".format(accuracy))

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize = (15, 10))
plt.subplot(2, 1, 1)
plt.plot(acc, label = 'Training Accuracy')
plt.plot(val_acc, label = 'Validation Accuracy')
plt.legend(loc = 'lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()), 1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label = 'Training Loss')
plt.plot(val_loss, label = 'Validation Loss')
plt.legend(loc = 'upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0, 1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

class_names = ['command', 'crosswalk', 'no_entry', 'speed_limit', 'warning']

model = tf.keras.models.load_model('/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/model/vgg_19.h5')

def classify(test_image):
    plt.imshow(test_image)
    test_image = tf.keras.preprocessing.image.img_to_array(test_image)
    test_image = np.expand_dims(test_image, axis = 0)

    result = model.predict(test_image)
    print(result)

    print(class_names[np.argmax(result)])

test_command = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/traffic_Data/test/command/command (5).jpg', target_size = (224, 224))

classify(test_command)

test_crosswalk = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/traffic_Data/test/crosswalk/crosswalk (5).jpg', target_size = (224, 224))

classify(test_crosswalk)

test_no_entry = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/traffic_Data/test/no_entry/no_entry (5).jpg', target_size = (224, 224))

classify(test_no_entry)

test_speed_limit = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/traffic_Data/test/speed_limit/speed_limit (5).jpg', target_size = (224, 224))

classify(test_speed_limit)

test_warning = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/4th/Deep Learning/Project/Deep Learning/traffic_Data/test/warning/warning (5).jpg', target_size = (224, 224))

classify(test_warning)

X_test, y_test = test_datagen.next()
predictions = model.predict(X_test)

y_pred = np.argmax(predictions, axis = 1)
y_true = np.argmax(y_test, axis = 1)

accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)
precision = sklearn.metrics.precision_score(y_true, y_pred, average = 'macro')
recall = sklearn.metrics.recall_score(y_true, y_pred, average = 'macro')
f1 = sklearn.metrics.f1_score(y_true, y_pred, average = 'macro')

confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)

print("Accuracy: {:.4f}".format(accuracy))
print("Precision: {:.4f}".format(precision))
print("Recall: {:.4f}".format(recall))
print("F1 Score: {:.4f}\n".format(f1))

sns.heatmap(confusion_matrix, annot = True)
plt.xlabel('Dự đoán')
plt.ylabel('Thực tế')
plt.show()